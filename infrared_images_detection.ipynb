{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOzT5rdJ8Cu4q0W2K+dlP19",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MSiswanto/MachineLearning/blob/main/infrared_images_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install"
      ],
      "metadata": {
        "id": "eXR-bCsZCt4y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip\n",
        "#!pip install --upgrade tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46GOEaywV5Kd",
        "outputId": "faf80513-18db-4e5b-a34a-369aa7bba62a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.9/dist-packages (22.0.4)\n",
            "Collecting pip\n",
            "  Downloading pip-23.0.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m68.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 22.0.4\n",
            "    Uninstalling pip-22.0.4:\n",
            "      Successfully uninstalled pip-22.0.4\n",
            "Successfully installed pip-23.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python-headless"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hf4mcTKhV8Uz",
        "outputId": "62773531-689c-4c0d-a7f3-d0ea965592c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.9/dist-packages (4.7.0.72)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.9/dist-packages (from opencv-python-headless) (1.22.4)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade scikit-image"
      ],
      "metadata": {
        "id": "C1JEIGs8uYxE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 736
        },
        "outputId": "f6f603f0-e605-49d4-9c19-4363d1f13c45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.9/dist-packages (0.19.3)\n",
            "Collecting scikit-image\n",
            "  Downloading scikit_image-0.20.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m84.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from scikit-image) (23.0)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image) (0.2)\n",
            "Collecting pillow>=9.0.1\n",
            "  Downloading Pillow-9.5.0-cp39-cp39-manylinux_2_28_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m81.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy<1.9.2,>=1.8\n",
            "  Downloading scipy-1.9.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image) (2.25.1)\n",
            "Requirement already satisfied: numpy>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image) (1.22.4)\n",
            "Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.9/dist-packages (from scikit-image) (3.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.9/dist-packages (from scikit-image) (2023.3.21)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image) (1.4.1)\n",
            "Installing collected packages: scipy, pillow, scikit-image\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.10.1\n",
            "    Uninstalling scipy-1.10.1:\n",
            "      Successfully uninstalled scipy-1.10.1\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: Pillow 8.4.0\n",
            "    Uninstalling Pillow-8.4.0:\n",
            "      Successfully uninstalled Pillow-8.4.0\n",
            "  Attempting uninstall: scikit-image\n",
            "    Found existing installation: scikit-image 0.19.3\n",
            "    Uninstalling scikit-image-0.19.3:\n",
            "      Successfully uninstalled scikit-image-0.19.3\n",
            "Successfully installed pillow-9.5.0 scikit-image-0.20.0 scipy-1.9.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Importing Library"
      ],
      "metadata": {
        "id": "iZaHK0H1uZ9d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gG0DXLCpCek0"
      },
      "outputs": [],
      "source": [
        "import os      \n",
        "import imutils\n",
        "import cv2\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display\n",
        "%matplotlib inline\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "from skimage.feature import hog\n",
        "from skimage import io\n",
        "from skimage.color import rgb2gray\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.svm import SVC"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resizing Images"
      ],
      "metadata": {
        "id": "Jrm2m509Crqb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "metadata": {
        "id": "s5LEStCeMv2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from google.colab import auth\n",
        "#auth.authenticate_user()\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNPhz6BiNXkn",
        "outputId": "faf7b8d2-ca17-46d7-9d8e-f69d12d511f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_image(row_id, root= \"/content/drive/MyDrive/images\"):\n",
        "    filename = \"image{:04d}.jpg\".format(row_id)\n",
        "    file_path = os.path.join(root, filename)\n",
        "    imag = Image.open(file_path)\n",
        "    img = imag.resize((64, 128))\n",
        "    return np.array(img)"
      ],
      "metadata": {
        "id": "beDnX5h0P7V4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load image using the get_image function\n",
        "img = get_image(row_id=1)\n",
        "\n",
        "# Display image using cv2_imshow\n",
        "cv2_imshow(img)"
      ],
      "metadata": {
        "id": "l1yeWzNFP_43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extracting Image HOG Features"
      ],
      "metadata": {
        "id": "U5mv8-8VDCsZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_features(img):\n",
        "    fd, hog_image = hog(image, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2), visualize=True, multichannel=False)\n",
        "    hog_image_rescaled = exposure.rescale_intensity(hog_image, in_range=(0, 10))\n",
        "    return fd\n"
      ],
      "metadata": {
        "id": "paYwu9NNuBIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage.color import rgb2gray\n",
        "\n",
        "def create_features(img):                                                 \n",
        "    \n",
        "    color_features = img.flatten()                                                    # flatten three channel color image\n",
        "    grey_image = rgb2gray(img)                                                        # convert image to greyscale\n",
        "    hog_features = hog(grey_image, block_norm='L2-Hys', pixels_per_cell=(2,2))        # get HOG features from greyscale image\n",
        "    flat_features = np.hstack(hog_features)                                           # combine color and hog features into a single array\n",
        "\n",
        "    return flat_features"
      ],
      "metadata": {
        "id": "qkl99w4LDAjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating HOG Features Matrix for Training Dataset"
      ],
      "metadata": {
        "id": "gnOUfpB_DWIF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_feature_matrix(label_dataframe): \n",
        "    \n",
        "    c=1\n",
        "    features_list = []                                   # List of Features of an Image\n",
        "    for img_id in label_dataframe.index:\n",
        "        img = get_image(img_id)                          # load image\n",
        "        image_features = create_features(img)            # get features for image\n",
        "        features_list.append(image_features)\n",
        "        print(c)                                         # Displays the count of Images converted to Vector\n",
        "        c+=1\n",
        "    feature_matrix = np.array(features_list)             # convert list of arrays into a matrix\n",
        "    return feature_matrix"
      ],
      "metadata": {
        "id": "DY15fVZmDdhZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PCA to reduce Dimensionality of Feature Matrix"
      ],
      "metadata": {
        "id": "eBGJ4xsFDipB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pcca(feature_matrix):\n",
        "                                   \n",
        "    print('Feature matrix shape is: ', feature_matrix.shape)           # get shape of feature matrix\n",
        "    ss = StandardScaler()                                              # define standard scaler\n",
        "    human_stand = ss.fit_transform(feature_matrix)                     # run this on our feature matrix\n",
        "    pca = PCA(n_components=50)                                         # set the number of components wisely, maybe less than 75\n",
        "    human_pca = pca.fit_transform(human_stand)                         # use fit_transform to run PCA on our standardized matrix\n",
        "    print('PCA matrix shape is: ', human_pca.shape)                    # look at new shape\n",
        "    return human_pca"
      ],
      "metadata": {
        "id": "X5BJqaeFDnuB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sliding Window Mechanism running throughout an Image"
      ],
      "metadata": {
        "id": "9Uil9RqLDuA5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sliding_window(image, stepSize, windowSize):\n",
        "    # slide a window across the image\n",
        "    for y in range(0, image.shape[0] - windowSize[1], stepSize):\n",
        "        for x in range(0, image.shape[1] - windowSize[0], stepSize):\n",
        "            # yield the current window\n",
        "            yield (x, y, image[y:y + windowSize[1], x:x + windowSize[0]])"
      ],
      "metadata": {
        "id": "CqQOsLarqMAq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#def sliding_window(image, stepSize, windowSize):\n",
        "    \n",
        "#    for y in range(0, image.shape[0], stepSize):                                  # slide a window across the image\n",
        "#        for x in range(0, image.shape[1], stepSize):                              # yield the current window\n",
        "#            yield (x, y, image[y:y + windowSize[1], x:x + windowSize[0]])\n",
        "                    "
      ],
      "metadata": {
        "id": "KmWo1t1EDw_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Non-Maximum Suppression for removing False Positive Regions"
      ],
      "metadata": {
        "id": "cxszmBAAD0rB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def non_max_suppression_fast(boxes, overlapThresh):\n",
        "    \n",
        "    if len(boxes) == 0:                                                  # if there are no boxes, return an empty list\n",
        "        return []\n",
        "    if boxes.dtype.kind == \"i\":                                          # if the bounding boxes integers, convert them to floats --\n",
        "        boxes = boxes.astype(\"float\")                                    # this is important since we'll be doing a bunch of divisions\n",
        "    pick = []                                                            # initialize the list of picked indexes\n",
        "    x1 = boxes[:,0]                                                      # grab the coordinates of the bounding boxes\n",
        "    y1 = boxes[:,1]\n",
        "    x2 = boxes[:,2]\n",
        "    y2 = boxes[:,3]\n",
        "    area = (x2 - x1 + 1) * (y2 - y1 + 1)                                 # compute the area of the bounding boxes \n",
        "    idxs = np.argsort(y2)                                                # sort the bounding boxes by the bottom-right y-coordinate of the bounding box\n",
        "    while len(idxs) > 0:                                                 # keep looping while some indexes still remain in the indexes list\n",
        "        last = len(idxs) - 1                                             # grab the last index in the indexes list  \n",
        "        i = idxs[last]                                                   \n",
        "        pick.append(i)                                                   # add the index value to the list of picked indexes\n",
        "        xx1 = np.maximum(x1[i], x1[idxs[:last]])                         # find the largest (x, y) coordinates for the start of the bounding box\n",
        "        yy1 = np.maximum(y1[i], y1[idxs[:last]])\n",
        "        xx2 = np.minimum(x2[i], x2[idxs[:last]])                         # find the smallest (x, y) coordinates for the end of the bounding box\n",
        "        yy2 = np.minimum(y2[i], y2[idxs[:last]])\n",
        "        w = np.maximum(0, xx2 - xx1 + 1)                                 # compute the width of the bounding box\n",
        "        h = np.maximum(0, yy2 - yy1 + 1)                                 # compute the height of the bounding box\n",
        "        overlap = (w * h) / area[idxs[:last]]                            # compute the ratio of overlap\n",
        "        idxs = np.delete(idxs, np.concatenate(([last],                   # delete all indexes from the index list that have\n",
        "            np.where(overlap > overlapThresh)[0])))\n",
        "    return boxes[pick].astype(\"int\")                                     # return only the bounding boxes that were picked using the integer data type"
      ],
      "metadata": {
        "id": "9GJmRUxKD4RB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Procedure for Image Dataset, using Support Vector Classifier"
      ],
      "metadata": {
        "id": "RYaS5J_lD8Zo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_feature_matrix(labels, img_dir):\n",
        "    feature_matrix = []\n",
        "    for i in range(len(labels)):\n",
        "        img_path = os.path.join(img_dir, labels.index[i])\n",
        "        img = cv2.imread(img_path)\n",
        "        feature_vector = np.array([cv2.mean(img)[:3]])\n",
        "        feature_matrix.append(feature_vector)\n",
        "    return np.vstack(feature_matrix)\n"
      ],
      "metadata": {
        "id": "J47nIAeF9DXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load image labels from a CSV file\n",
        "labels = pd.read_csv(\"/content/drive/MyDrive/labels.csv\", index_col=0)  #/content/sample_data/_annotations.csv\", index_col=0)\n",
        "\n",
        "# Set the directory where the image files are stored\n",
        "img_dir = \"/content/drive/MyDrive/images\" #/content/drive/MyDrive/images\"\n",
        "\n",
        "# Create a feature matrix from the images\n",
        "feature_matrix = create_feature_matrix(labels, img_dir)\n"
      ],
      "metadata": {
        "id": "CbQl3SpW9XfB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Generate random feature matrix with 100 samples and 10 features\n",
        "feature_matrix = np.random.randn(500, 2266)\n",
        "\n",
        "# Generate a small feature matrix with only 3 samples and 2 features\n",
        "#feature_matrix = np.array([[1, 2], [3, 4], [5, 6]])\n",
        "\n",
        "# Try to perform PCA with n_components=50\n",
        "try:\n",
        "    pca = PCA(n_components=50)\n",
        "    X_pca = pca.fit_transform(feature_matrix)\n",
        "except ValueError as e:\n",
        "    # Handle the error by reducing the number of components\n",
        "    print(f\"Error: {e}\")\n",
        "    max_components = min(feature_matrix.shape)\n",
        "    pca = PCA(n_components=max_components)\n",
        "    X_pca = pca.fit_transform(feature_matrix)\n",
        "\n",
        "    # Perform principal component analysis  \n",
        "    X_train = pca.fit_transform(feature_matrix)\n",
        "    X_train = pd.DataFrame(X_train)\n",
        "\n",
        "    # Access the labels of training images\n",
        "    y_train = pd.Series(labels.label.values)\n",
        "\n",
        "    # Train a support vector classifier\n",
        "    svm = SVC(kernel='rbf', C=1.0, gamma='scale', probability=True, random_state=42)\n",
        "    svm.fit(X_train, y_train)\n",
        "\n",
        "    # Look at the distribution of labels in the train set\n",
        "    pd.Series(y_train).value_counts()\n",
        "    \n",
        "print(f\"Original shape: {feature_matrix.shape}\")\n",
        "print(f\"Reduced shape: {X_pca.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZf9PLMtk3tz",
        "outputId": "3dc7d2b5-00dd-4deb-a7ee-5facb545df73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original shape: (500, 2266)\n",
            "Reduced shape: (500, 50)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Reshape y to have shape of (n,)\n",
        "y = np.array(1 if i in positive_indexes else 0 for i in range(len(t))).reshape(-1, 1)\n",
        "#y = y.ravel()\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(feature_matrix, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Train an SVM classifier\n",
        "svm = SVC(kernel='linear', probability=True)  #svm = SVC(kernel='linear', C=1.0, random_state=42)\n",
        "svm.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the classifier\n",
        "accuracy = svm.score(X_test, y_test)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "id": "clycnBw-71Kf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Applying Trained Model to Detect Human in a Test Image\n"
      ],
      "metadata": {
        "id": "9zTt52zLEHAp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "def non_max_suppression(boxes, overlapThresh):\n",
        "    if len(boxes) == 0:\n",
        "        return []\n",
        "\n",
        "    # initialize the list of picked indexes\n",
        "    pick = []\n",
        "\n",
        "    # grab the coordinates of the bounding boxes\n",
        "    x1 = boxes[:, 0]\n",
        "    y1 = boxes[:, 1]\n",
        "    x2 = boxes[:, 2]\n",
        "    y2 = boxes[:, 3]\n",
        "\n",
        "    # compute the area of the bounding boxes and sort the bounding\n",
        "    # boxes by the bottom-right y-coordinate of the bounding box\n",
        "    area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
        "    idxs = np.argsort(y2)\n",
        "\n",
        "    # keep looping while some indexes still remain in the indexes\n",
        "    # list\n",
        "    while len(idxs) > 0:\n",
        "        # grab the last index in the indexes list and add the\n",
        "        # index value to the list of picked indexes\n",
        "        last = len(idxs) - 1\n",
        "        i = idxs[last]\n",
        "        pick.append(i)\n",
        "\n",
        "        # find the largest (x, y) coordinates for the start of\n",
        "        # the bounding box and the smallest (x, y) coordinates\n",
        "        # for the end of the bounding box\n",
        "        xx1 = np.maximum(x1[i], x1[idxs[:last]])\n",
        "        yy1 = np.maximum(y1[i], y1[idxs[:last]])\n",
        "        xx2 = np.minimum(x2[i], x2[idxs[:last]])\n",
        "        yy2 = np.minimum(y2[i], y2[idxs[:last]])\n",
        "\n",
        "        # compute the width and height of the bounding box\n",
        "        w = np.maximum(0, xx2 - xx1 + 1)\n",
        "        h = np.maximum(0, yy2 - yy1 + 1)\n",
        "\n",
        "        # compute the ratio of overlap between the computed\n",
        "        # bounding box and the bounding boxes in the boxes list,\n",
        "        # and update the indexes list\n",
        "        overlap = (w * h) / area[idxs[:last]]\n",
        "        idxs = np.delete(idxs, np.concatenate(([last],\n",
        "            np.where(overlap > overlapThresh)[0])))\n",
        "\n",
        "    # return only the bounding boxes that were picked using the\n",
        "    # integer data type\n",
        "    return boxes[pick].astype(\"int\")\n"
      ],
      "metadata": {
        "id": "u7Lb-HfErV8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from imutils.object_detection import non_max_suppression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "from skimage.color import rgb2gray"
      ],
      "metadata": {
        "id": "UUy7IhlkefBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "image = cv2.imread(\"/content/drive/MyDrive/images/image0001.jpg\")    \n",
        "#image = cv2.imread(r\"/content/drive/MyDrive/dataset_irimage/\")    \n",
        "\n",
        "scale_percent = 200                                                                         # percent of original size\n",
        "width = int(image.shape[1] * scale_percent / 100)\n",
        "height = int(image.shape[0] * scale_percent / 100)\n",
        "dim = (width, height)                   \n",
        "                                                                                            # New dimensions of Image Window\n",
        "image = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)  \n",
        "\n",
        "(winW , WinH) = (64 , 128)    \n",
        "winH = 128                                                              # Dimensions of Sliding Window\n",
        "t=[]                                                                                        # Feature Matrix for test image portions\n",
        "k=[]       \n",
        "                                                                                            # Indexes corresponding to image portions\n",
        "for (x, y, window) in sliding_window(image, stepSize=16, windowSize=(winW, winH)):          # loop over the sliding window for each layer of the pyramid\n",
        "    if window.shape[0] != winH or window.shape[1] != winW:                                  # if the window does not meet our desired window size, ignore it\n",
        "        continue           \n",
        "\n",
        "    clone = image.copy()\n",
        "    op=clone[y:y + winH, x:x + winW]\n",
        "    f = create_features(op)\n",
        "    t.append(f)\n",
        "    k.append([x,y])\n",
        "    cv2.rectangle(clone, (x, y), (x + winW, y + winH), (0, 255, 0), 2)\n",
        "    cv2_imshow(clone) #(\"Window\", clone)\n",
        "    cv2.waitKey(1)\n",
        "    time.sleep(0.025)\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "# THIS IS WHERE YOU WOULD PROCESS YOUR WINDOW, SUCH AS APPLYING A MACHINE LEARNING CLASSIFIER TO CLASSIFY THE CONTENTS OF THE WINDOW\n",
        "# since we do not have a classifier, we'll just draw the window\n",
        "\n",
        "hpp=pcca(t)\n",
        "x_p=pd.DataFrame(hpp)\n",
        "y_p=svm.predict(x_p)\n",
        "pp=list(y_p)                                                                                # Predict the portions where human is detected\n",
        "clon = image.copy()\n",
        "nn=[]                                                                                       # List of indexes of Human Detection Portions\n",
        "for i in range(0,len(pp)):\n",
        "    if pp[i]==1.0:\n",
        "        x=k[i][0]\n",
        "        y=k[i][1]\n",
        "        nn.append([x,y,x+winW,y+winH])\n",
        "        cv2.rectangle(clon, (x, y), (x + winW, y + winH), (0, 255, 0), 2)\n",
        "        cv2.imshow(\"Window\", clon)\n",
        "        cv2.waitKey(50)\n",
        "        time.sleep(0.025)\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "ll=non_max_suppression_fast(np.array(nn),0.4)                                              # Applied Non-Max Suppression on Human Detected portions\n",
        "l=list(ll)                                                                                 # List of Indexes of Actual Human Regions \n",
        "clo=image.copy()\n",
        "for kl in l:\n",
        "    cv2.rectangle(clo, (kl[0], kl[1]), (kl[2],kl[3]), (0, 255, 0), 1)                      # Display the most probable Detection Regions out of False Positives\n",
        "    cv2_imshow(clo)\n",
        "    cv2.waitKey(0)\n",
        "    time.sleep(0.025)\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "lctDc9PMEC3C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}